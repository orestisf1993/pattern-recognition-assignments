Η πρώτη προσπάθεια υλοποίησης του αλγορίθμου KNN πραγματοποιήθηκε για k=1.
Παρατηρούμε παραπάνω ότι τόσο το f-measure όσο και το recall της κλάσης 1 είναι πολύ χαμηλά.
Προφανώς αυτό το μοντέλο δεν μας δίνει το βέλτιστο αποτέλεσμα.
Ωστόσο, είναι χρήσιμο να αναφέρουμε ότι το ρίσκο σε έναν αλγόριθμο ταξινόμησης 1NN είναι το περισσότερο διπλάσιος από το ρίσκο ενός ταξινομητή Bayes αλλά δεν μπορούμε να είμαστε σίγουροι ότι αυτός ο ταξινομητής θα είναι σταθερός.
Με κατάλληλη επιλογή του μεγέθους των δειγμάτων το bagging μπορεί να οδηγήσει σε ουσιαστικές βελτιώσεις της απόδοσης του 1ΝΝ ταξινομητή.

