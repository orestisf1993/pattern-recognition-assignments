
\chapter{Εκτέλεση Αλγορίθμων}

Αφού ολοκληρώσαμε την επεξεργασία των δεδομένων μας (dataset) εφαρμόσαμε τους αλγορίθμους που αναφέραμε παραπάνω για την επίλυση του προβλήματος. Για κάθε αλγόριθμο υπολογίσαμε τις μετρικές του πάνω στο σετ εκπαίδευσης (training set)και στο τέλος συγκρίνουμε την απόδοση των αλγορίθμων. Οι αλγόριθμοι που χρησιμοποιήσαμε ανήκουν στις κατηγορίες Bayes, Trees, SVM και NNs.

\section{Bayes}

\section{Trees}
\input{algorithms/j48}
\input{algorithms/random-forest}
\section{Support Vector Machine (SVM)}

Γενική Ιδέα: H γενική ιδέα της μεθόδου SVM είναι η εύρεση ενός υπερεπίπεδου το οποίο θα διαχωρίζει τα δεδομένα. Το υπερεπίπεδο αυτό καλείται όριο απόφασης. 

\begin{figure}[h!]
	\includegraphics{SVMphoto.jpg}
	\caption {SVM example}
	\label{fig:SVM}  
\end{figure}

Όπως βλέπουμε και από το Σχήμα 3.1 παραπάνω τα δεδομένα μας χωρίζονται σε 2 κλάσεις. Βρίσκουμε τα Support Vector των 2 κλάσεων που είναι τα δεδομένα των 2 κλάσεων που απέχουν την μικρότερη απόσταση μεταξύ και προσπαθούμε να βρούμε το υπερεπίπεδο το οποίο μεγιστοποιεί το περιθώριο (margin) μεταξύ των Support Vector. Ουσιαστικά στον SVM θέλουμε να μεγιστοποιήσουμε αυτό το περιθώριο.


Ο αλγόριθμος SVM περιγράφεται μαθηματικά από τις παρακάτω εξισώσεις:
\newline
Θέλουμε να μεγιστοποιήσουμε την ποσότητα   $ Margin=\frac{2}{|w\|^2} $
\newline
Ισοδύναμα θέλουμε να ελαχιστοποιήσουμε την ποσότητα  $ L(w)=\frac{|w\|^2}{2} $
\newline
	Αλλά δεδομένων των παρακάτω περιορισμών:


 $f(x_i)$ 
$ = \begin{cases} 1, & \mbox{if } w\cdot\mbox{ $x_i +b \geq 1 $} \\ -1, & \mbox{if } w\cdot\mbox{ $x_i +b \leq -1 $} \end{cases} $


 Ουσιαστικά πρόκειται για ένα πρόβλημα βελτιστοποίησης υπό περιορισμούς.
 Το πρόβλημα βελτιστοποίησης έχει λύση της μορφής :
\newline $\boldsymbol  w $=$\sum a_i y_i \boldsymbol x_i $ $b$=$y_k$-$\boldsymbol w^T \boldsymbol x_k$ για κάθε $\boldsymbol x_k$ τέτοιο ώστε $a_k\not= 0$
 
 Για κάθε μη-μηδενικό $a_i$ συνεπάγεται ότι το $\boldsymbol x_i$ είναι Support Vector
 
 Η συνάρτηση ταξινόμησης που χρησιμοποιεί ο SVM έχει την μορφή:
\begin{align*} 
f(x)=\sum a_i y_i \boldsymbol {x_i}^T \boldsymbol x_i +b
\end{align*}

Ο SVM είναι ιδιαίτερα αποδοτικός όταν τα δεδομένα εισόδου είναι γραμμικά διαχωρίσιμα. Ωστόσο μπορούμε να εφαρμόσουμε τον αλγόριθμο και στην περίπτωση που τα δεδομένα εισόδου δεν είναι γραμμικά διαχωρίσιμα χρησιμοποιώντας την τεχνική "kernel trick". Με αυτήν την τεχνική ουσιαστικά τοποθετούμε τα δεδομένα εισόδου σε μεγαλύτερο χώρο διαστάσεων χωρίς να υπολογίσουμε αναλυτικά τις συντεταγμένες των δεδομένων αυτών. Πρόκειται λοιπόν για μια αποδοτική τεχνική που μας επιτρέπει την χρήση του SVM σε κάθε περίπτωση.

Εξετάστηκαν 2 διαφορετικοί αλγόριθμοι SVM.Οι αλγόριθμοι που θα χρησιμοποιήσουμε στο Weka είναι ο SMO και ο LibSVM.O Sequential minimal optimization(SMO) σπάει το πρόβλημα σε μικρότερα προβλήματα τα οποία λύνονται αναλυτικά. Χρησιμοποιούνται για την επίλυση προβλήματων quadratic programming .Το βασικό πλεονέκτημα του SMO είναι ότι είναι ελάχιστα ταχύτερο στην εκπαίδευση. O LibSVM είναι ο πιο δημοφιλής τρόπος για να εκπαιδεύσεις SVM.
 
\section{KNN}

Γενική Ιδέα: Η μέθοδος αυτή βασίζεται στην εξεύρεση των k κοντινότερων γειτονικών σημείων του δείγματος προς ταξινόμηση.

\begin{center}
	\includegraphics{Knnphoto.png}
	\captionof{figure}{KNN example}
	\label{fig:KNN}  
\end{center}

Όπως βλέπουμε και στο παραπάνω σχήμα το δείγμα προς ταξινόμηση συμβολίζεται με το αστεράκι.Βλέπουμε ένα παράδειγμα για k=3 όπου συλλέγουμε τους 3 κοντινότερους γείτονες και όμοια για k=6.

Ο ταξινομητής ΚΝΝ απαιτεί:
\begin{enumerate}
	\item Το σετ εκπαίδευσης
	\item Μια μετρική απόστασης όπου συνήθως χρησιμοποιείται η Ευκλείδια Απόσταση
	\item Η παράμετρος k που δηλώνει τον αριθμό των k γειτόνων που θα χρησιμοποιηθεί
\end{enumerate}

Η πιο σημαντική παράμετρος που πρέπει να επιλεγεί είναι ο αριθμός των γειτόνων(k παράμετρος).Μικρές τιμές του k κάνουν τον ταξινομητή μας ευαίσθητο στον θόρυβο ενώ πολύ μεγάλες τιμές μπορούν να κάνουν την γειτονιά μας να περιέχει και σημεία από άλλες κλάσεις τα οποία όμως βρίσκονται πολύ μακριά από το δειγμα προς ταξινόμηση.
\input{algorithms/ibk}